{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交通讯号灯分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第0步: 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pickled data\n",
    "import pickle\n",
    "\n",
    "# TODO: Fill this in based on where you saved the training and testing data\n",
    "\n",
    "training_file = 'traffic-signs-data/train.p'\n",
    "validation_file = 'traffic-signs-data/valid.p'\n",
    "testing_file = 'traffic-signs-data/test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 第1步: 数据总结和浏览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replace each question mark with the appropriate value. \n",
    "### Use python, pandas or numpy methods rather than hard coding the results\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "# TODO: Number of training examples\n",
    "n_train = len(X_train)\n",
    "\n",
    "# TODO: Number of validation examples\n",
    "n_validation = len(X_valid)\n",
    "\n",
    "# TODO: Number of testing examples.\n",
    "n_test = len(X_test)\n",
    "\n",
    "# TODO: What's the shape of an traffic sign image?\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "# TODO: How many unique classes/labels there are in the dataset.\n",
    "n_classes = len(collections.Counter(y_train))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 部分数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data exploration visualization code goes here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "randoms = []\n",
    "# show image of 15 random data points\n",
    "fig, axs = plt.subplots(3,5, figsize=(5,4))\n",
    "axs = axs.ravel()\n",
    "for i in range(15):\n",
    "    index = random.randint(0, n_train)\n",
    "    randoms.append(index)\n",
    "    image = X_train[index]\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(image)\n",
    "    axs[i].set_title(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show the gray color\n",
    "fig, axs = plt.subplots(3,5, figsize=(5,4))\n",
    "axs = axs.ravel()\n",
    "for i in range(15):\n",
    "    index = randoms[i]\n",
    "    randoms.append(index)\n",
    "    image = X_train[index]\n",
    "    gray = np.mean(image, axis=2)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(gray, cmap='gray')\n",
    "    axs[i].set_title(y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print y_train\n",
    "print(y_train[0:200])\n",
    "print()\n",
    "print(y_train[-200:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以这些数据必须随机化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "X_valid, y_valid = shuffle(X_valid, y_valid)\n",
    "X_test, y_test = shuffle(X_test, y_test)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of label frequency\n",
    "hist, bins = np.histogram(y_train, bins=n_classes)\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center',)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no imformation from the histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第2步：设计和测试模型架构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预处理数据集 （归一化，灰度化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess the data here. It is required to normalize the data. Other preprocessing steps could include \n",
    "### converting to grayscale, etc.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# Convert to grayscale\n",
    "X_train_gray = np.sum(X_train/3, axis=3, keepdims=True)\n",
    "X_valid_gray = np.sum(X_valid/3, axis=3, keepdims=True)\n",
    "X_test_gray = np.sum(X_test/3, axis=3, keepdims=True)\n",
    "print('X_train_gray shape:', X_train_gray.shape)\n",
    "\n",
    "## Normalize the train and test datasets to (-1,1)\n",
    "X_train_normalized = (X_train_gray - 128)/128 \n",
    "X_valid_normalized = (X_valid_gray - 128)/128\n",
    "X_test_normalized = (X_test_gray - 128)/128\n",
    "\n",
    "X_train = X_train_normalized\n",
    "X_valid = X_valid_normalized\n",
    "X_test = X_test_normalized\n",
    "print('X_train shape:', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型架构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用LeNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I use LeNet\n",
    "![LeNet](examples/lenet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LeNet(x):\n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    # TODO: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean=mu, stddev=sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding=\"VALID\") + conv1_b\n",
    "    # TODO: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    layer1 = conv1\n",
    "    # TODO: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    layer2 = conv1\n",
    "\n",
    "    # TODO: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean=mu, stddev=sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2 = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding=\"VALID\") + conv2_b\n",
    "    # TODO: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    layer3 = conv2\n",
    "    # TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    layer4 = conv2\n",
    "\n",
    "    # TODO: Flatten. Input = 5x5x16. Output = 400.\n",
    "    fc0 = flatten(conv2)\n",
    "    # TODO: Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(400, 120), mean=mu, stddev=sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(120))\n",
    "    fc1 = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    # TODO: Activation.\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # TODO: Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W = tf.Variable(tf.truncated_normal(shape=(120, 84), mean=mu, stddev=sigma))\n",
    "    fc2_b = tf.Variable(tf.zeros(84))\n",
    "    fc2 = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    # TODO: Activation.\n",
    "    fc2 = tf.nn.relu(fc2)\n",
    "    # TODO: Layer 5: Fully Connected. Input = 84. Output = 43.\n",
    "    fc3_W = tf.Variable(tf.truncated_normal(shape=(84, 43), mean=mu, stddev=sigma))\n",
    "    fc3_b = tf.Variable(tf.zeros(43))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    return logits, layer1, layer2, layer3, layer4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "使用得改进版LeNet 论文见：http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Change The Network](examples/20170410235258.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LeNet2(x):\n",
    "    # Hyperparameters\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    # TODO: Layer 1: Convolutional. Input = 32x32x1. Output = 28x28x6.\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 1, 6), mean=mu, stddev=sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(6))\n",
    "    conv1 = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding=\"VALID\") + conv1_b\n",
    "    # TODO: Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    layer1 = conv1\n",
    "    # TODO: Pooling. Input = 28x28x6. Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    layer2 = conv1\n",
    "\n",
    "    # TODO: Layer 2: Convolutional. Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 6, 16), mean=mu, stddev=sigma), name=\"W2\")\n",
    "    conv2_b = tf.Variable(tf.zeros(16))\n",
    "    conv2 = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding=\"VALID\") + conv2_b\n",
    "    # TODO: Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    layer3 = conv2\n",
    "    # TODO: Pooling. Input = 10x10x16. Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    layer4 = conv2\n",
    "\n",
    "    # TODO: Layer 3: Convolutional. Output = 1x1x400.\n",
    "    conv3_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 16, 400), mean=mu, stddev=sigma))\n",
    "    conv3_b = tf.Variable(tf.zeros(400), name=\"b3\")\n",
    "    conv3 = tf.nn.conv2d(conv2, conv3_W, strides=[1, 1, 1, 1], padding='VALID')\n",
    "    conv3 = tf.nn.bias_add(conv3, conv3_b)\n",
    "    # TODO: Activation.\n",
    "    conv3 = tf.nn.relu(conv3)\n",
    "\n",
    "    # TODO: Flatten. Input = 5x5x16. Output = 400.\n",
    "    fc0 = flatten(conv2)\n",
    "    print(\"layer2flat shape:\", fc0.get_shape())\n",
    "\n",
    "    # Flatten x. Input = 1x1x400. Output = 400.\n",
    "    fc1 = flatten(conv3)\n",
    "    print(\"xflat shape:\", fc1.get_shape())\n",
    "    # Concat layer2flat and x. Input = 400 + 400. Output = 800\n",
    "    fc2 = tf.concat([fc0, fc1], 1)\n",
    "    print(\"fc2 shape:\", fc2.get_shape())\n",
    "    # Dropout\n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "\n",
    "    # TODO: Layer 4: Fully Connected. Input = 800. Output = 43.\n",
    "    fc3_W = tf.Variable(tf.truncated_normal(shape=(800, 43), mean=mu, stddev=sigma), name=\"W4\")\n",
    "    fc3_b = tf.Variable(tf.zeros(43), name=\"b4\")\n",
    "    logits = tf.add(tf.matmul(fc2, fc3_W), fc3_b)\n",
    "\n",
    "    return logits, layer1, layer2, layer3, layer4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练，验证和测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Train your model here.\n",
    "### Calculate and report the accuracy on the training and validation set.\n",
    "### Once a final model architecture is selected, \n",
    "### the accuracy on the test set should be calculated and reported as well.\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "#parameters\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = int(n_train/BATCH_SIZE) + 1  #use all the train data\n",
    "rate = 0.001\n",
    "dropout = 0.5\n",
    "\n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 1))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "one_hot_y = tf.one_hot(y, 43)\n",
    "\n",
    "logits, layer1, layer2, layer3, layer4 = LeNet(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training and valid\n",
    "saver = tf.train.Saver()\n",
    "if True:\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        num_examples = len(X_train)\n",
    "\n",
    "        print(\"Training...\")\n",
    "        print()\n",
    "        for i in range(EPOCHS):\n",
    "            for offset in range(0, num_examples, BATCH_SIZE):\n",
    "                end = offset + BATCH_SIZE\n",
    "                batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "                sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "\n",
    "            validation_accuracy = evaluate(X_valid, y_valid)\n",
    "            print(\"EPOCH {} / {}: Validation Accuracy = {:.3f}\".format(i + 1, EPOCHS, validation_accuracy))\n",
    "\n",
    "        saver.save(sess, './lenet')\n",
    "        print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing the model\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./lenet\")\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))\n",
    "    test_accuracy = evaluate(X_train, y_train)\n",
    "    print(\"Train Accuracy = {:.3f}\".format(test_accuracy))\n",
    "    test_accuracy = evaluate(X_valid, y_valid)\n",
    "    print(\"Valid Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 这里用优化后的Lenet来做"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, layer1, layer2, layer3, layer4 = LeNet2(x)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=one_hot_y)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "### Training and valid\n",
    "if True:\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        num_examples = len(X_train)\n",
    "\n",
    "        print(\"Training...\")\n",
    "        print()\n",
    "        for i in range(EPOCHS):\n",
    "            for offset in range(0, num_examples, BATCH_SIZE):\n",
    "                end = offset + BATCH_SIZE\n",
    "                batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "                sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "\n",
    "            validation_accuracy = evaluate(X_valid, y_valid)\n",
    "            print(\"EPOCH {} / {}: Validation Accuracy = {:.3f}\".format(i + 1, EPOCHS, validation_accuracy))\n",
    "\n",
    "        saver.save(sess, './lenet')\n",
    "        print(\"Model lenet saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing the model\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./lenet\")\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))\n",
    "    test_accuracy = evaluate(X_train, y_train)\n",
    "    print(\"Train Accuracy = {:.3f}\".format(test_accuracy))\n",
    "    test_accuracy = evaluate(X_valid, y_valid)\n",
    "    print(\"Valid Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 第3步：在新数据上使用模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load the images and plot them here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "#reading in an image\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "fig, axs = plt.subplots(2,4, figsize=(4, 2))\n",
    "fig.subplots_adjust(hspace = .2, wspace=.001)\n",
    "axs = axs.ravel()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "my_images = []\n",
    "\n",
    "for i, img in enumerate(glob.glob('./my-found-traffic-signs/*x.png')):\n",
    "    image = cv2.imread(img)\n",
    "    axs[i].axis('off')\n",
    "    axs[i].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    my_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grayscale and normalized\n",
    "my_images = np.asarray(my_images)\n",
    "my_images_gry = np.sum(my_images/3, axis=3, keepdims=True)\n",
    "my_images_normalized = (my_images_gry - 128)/128\n",
    "print(my_images_normalized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 给每个图片预测交通信号类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Run the predictions here and use the model to output the prediction for each image.\n",
    "### Make sure to pre-process the images with the same pre-processing pipeline used earlier.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.restore(sess, \"./lenet\")\n",
    "    y_predict = sess.run(tf.argmax(logits, 1), feed_dict={x: my_images_normalized, keep_prob: dropout})\n",
    "    print(\"predict result is: \", y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the Result is [ 3 11  1 12 38 34 18 25]\n",
    "\n",
    "in the signnames.csv\n",
    "\n",
    "- 3 - Speed limit (60km/h)\n",
    "- 11 - Right-of-way at the next intersection\n",
    "- 1 - Speed limit (30km/h)\n",
    "- 12 - Priority road\n",
    "- 38 - Keep right\n",
    "- 34 - Turn left ahead\n",
    "- 18 - General caution\n",
    "- 25 - Road work\n",
    "\n",
    "the 3rd is wrong, but it is Speed limit (30km/h),not (50km/h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分析准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Calculate the accuracy for these 5 new images. \n",
    "### For example, if the model predicted 1 out of 5 signs correctly, it's 20% accurate on these new images.\n",
    "my_labels = [3, 11, 1, 12, 38, 34, 18, 25]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    correct_prediction = tf.equal(tf.constant(my_labels), tf.constant(y_predict.astype(np.int32)))\n",
    "    accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    my_accuracy = sess.run(accuracy_operation)\n",
    "    print(\"Test Set Accuracy = {:.3f}\".format(my_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Set Accuracy = 1.000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 输出每个图像的前5个Softmax概率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the new images, print out the model's softmax probabilities to show the **certainty** of the model's predictions (limit the output to the top 5 probabilities for each image). [`tf.nn.top_k`](https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#top_k) could prove helpful here. \n",
    "\n",
    "The example below demonstrates how tf.nn.top_k can be used to find the top k predictions for each image.\n",
    "\n",
    "`tf.nn.top_k` will return the values and indices (class ids) of the top k predictions. So if k=3, for each sign, it'll return the 3 largest probabilities (out of a possible 43) and the correspoding class ids.\n",
    "\n",
    "Take this numpy array as an example. The values in the array represent predictions. The array contains softmax probabilities for five candidate images with six possible classes. `tk.nn.top_k` is used to choose the three classes with the highest probability:\n",
    "\n",
    "```\n",
    "# (5, 6) array\n",
    "a = np.array([[ 0.24879643,  0.07032244,  0.12641572,  0.34763842,  0.07893497,\n",
    "         0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.08594638,  0.0178669 ,  0.18063401,\n",
    "         0.15899337],\n",
    "       [ 0.26076848,  0.23664738,  0.08020603,  0.07001922,  0.1134371 ,\n",
    "         0.23892179],\n",
    "       [ 0.11943333,  0.29198961,  0.02605103,  0.26234032,  0.1351348 ,\n",
    "         0.16505091],\n",
    "       [ 0.09561176,  0.34396535,  0.0643941 ,  0.16240774,  0.24206137,\n",
    "         0.09155967]])\n",
    "```\n",
    "\n",
    "Running it through `sess.run(tf.nn.top_k(tf.constant(a), k=3))` produces:\n",
    "\n",
    "```\n",
    "TopKV2(values=array([[ 0.34763842,  0.24879643,  0.12789202],\n",
    "       [ 0.28086119,  0.27569815,  0.18063401],\n",
    "       [ 0.26076848,  0.23892179,  0.23664738],\n",
    "       [ 0.29198961,  0.26234032,  0.16505091],\n",
    "       [ 0.34396535,  0.24206137,  0.16240774]]), indices=array([[3, 0, 5],\n",
    "       [0, 1, 4],\n",
    "       [0, 5, 1],\n",
    "       [1, 3, 5],\n",
    "       [1, 4, 3]], dtype=int32))\n",
    "```\n",
    "\n",
    "Looking just at the first row we get `[ 0.34763842,  0.24879643,  0.12789202]`, you can confirm these are the 3 largest probabilities in `a`. You'll also notice `[3, 0, 5]` are the corresponding indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Print out the top five softmax probabilities for the predictions on the German traffic sign images found on the web. \n",
    "### Feel free to use as many code cells as needed.\n",
    "k = 5\n",
    "softmax_logits = tf.nn.softmax(logits)\n",
    "top_k = tf.nn.top_k(softmax_logits, k=k)\n",
    "my_top_k = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./lenet\")\n",
    "    my_softmax_logits = sess.run(softmax_logits, feed_dict={x: my_images_normalized, keep_prob: 0.5})\n",
    "    my_top_k = sess.run(top_k, feed_dict={x: my_images_normalized, keep_prob: 0.5})\n",
    "    \n",
    "    print(my_top_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the pictures \n",
    "fig, axs = plt.subplots(len(my_images),(k+1), figsize=(12, 20))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, image in enumerate(my_images):\n",
    "    axs[(k+1)*i].axis('off')\n",
    "    axs[(k+1)*i].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    axs[(k+1)*i].set_title('input')\n",
    "    for j in range(k):\n",
    "        guess = my_top_k[1][i][j]\n",
    "        index = np.argwhere(y_train == guess)[0]\n",
    "        axs[(k+1)*i+j+1].axis('off')\n",
    "        axs[(k+1)*i+j+1].imshow(X_train[index].squeeze(), cmap='gray')\n",
    "        axs[(k+1)*i+j+1].set_title('guest {}: ({:.0f}%)'.format(guess, 100*my_top_k[0][i][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 第4步：使用测试图像可视化神经网络的状态\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Visualize your network's feature maps here.\n",
    "### Feel free to use as many code cells as needed.\n",
    "\n",
    "# image_input: the test image being fed into the network to produce the feature maps\n",
    "# tf_activation: should be a tf variable name used during your training procedure that represents the calculated state of a specific weight layer\n",
    "# activation_min/max: can be used to view the activation contrast in more detail, by default matplot sets min and max to the actual min and max values of the output\n",
    "# plt_num: used to plot out multiple different weight feature map sets on the same block, just extend the plt number for each new feature map entry\n",
    "\n",
    "def outputFeatureMap(image_input, tf_activation, activation_min=-1, activation_max=-1 ,plt_num=1):\n",
    "    # Here make sure to preprocess your image_input in a way your network expects\n",
    "    # with size, normalization, ect if needed\n",
    "    # image_input =\n",
    "    # Note: x should be the same name as your network's tensorflow data placeholder variable\n",
    "    # If you get an error tf_activation is not defined it may be having trouble accessing the variable from inside a function\n",
    "    activation = tf_activation.eval(session=sess,feed_dict={x : image_input})\n",
    "    featuremaps = activation.shape[3]\n",
    "    plt.figure(plt_num, figsize=(15,15))\n",
    "    for featuremap in range(featuremaps):\n",
    "        plt.subplot(6,8, featuremap+1) # sets the number of feature maps to show on each row and column\n",
    "        plt.title('FeatureMap ' + str(featuremap)) # displays the feature map number\n",
    "        if activation_min != -1 & activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin =activation_min, vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_max != -1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmax=activation_max, cmap=\"gray\")\n",
    "        elif activation_min !=-1:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", vmin=activation_min, cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imshow(activation[0,:,:, featuremap], interpolation=\"nearest\", cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the first layer before maxpooling\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./lenet\")\n",
    "    print(\"Feature Map Stage 1:\")\n",
    "    outputFeatureMap(my_images_normalized, layer1, plt_num=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show the second layer before maxpooling\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./lenet\")\n",
    "    print(\"Feature Map Stage 2:\")\n",
    "    outputFeatureMap(my_images_normalized, layer2, plt_num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./lenet\")\n",
    "    print(\"Feature Map Stage 3:\")\n",
    "    outputFeatureMap(my_images_normalized, layer3, plt_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./lenet\")\n",
    "    print(\"Feature Map Stage 4:\")\n",
    "    outputFeatureMap(my_images_normalized, layer4, plt_num=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
